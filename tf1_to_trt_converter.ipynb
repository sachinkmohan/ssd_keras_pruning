{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = './saved_models/base_models/1502/ssd7_base_epoch-30_loss-2.0457_val_loss-2.2370.h5'\n",
    "\n",
    "#model_path = './saved_models/base_model_13_01/trained_a_base_model_1301.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "#K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "#model = load_model(model_path, custom_objects={'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports of the SSD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd7 import build_model\n",
    "#from models.keras_ssd7_quantize import build_model_quantize\n",
    "from models.keras_ssd7_quantize2 import build_model_quantize2\n",
    "#from keras_loss_function.keras_ssd_loss import SSDLoss  #commented to test TF2.0\n",
    "from keras_loss_function.keras_ssd_loss_tf2 import SSDLoss # added for TF2.0\n",
    "\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_AnchorBoxes_1 import DefaultDenseQuantizeConfig\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
    "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "\n",
    "## imports used for pruning\n",
    "import tensorflow_model_optimization as tfmot \n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "## loading tensorboard\n",
    "\n",
    "#%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1'] ['predictions/concat']\n",
      "INFO:tensorflow:Froze 58 variables.\n",
      "INFO:tensorflow:Converted 58 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# force reset ipython namespaces\n",
    "%reset -f\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "save_pb_dir = './output_saved_model_dir'\n",
    "model_fname = './trained_models_local/ssd7_base_epoch-29_loss-2.0919_val_loss-2.2598.h5'\n",
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model_ep29.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "tf.keras.backend.set_learning_phase(0) \n",
    "\n",
    "#Custom code for loading this SSD Model\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "#K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_fname, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "#model = load_model(model_fname)\n",
    "\n",
    "##Custom code for loading the model ends here\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "\n",
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]\n",
    "\n",
    "# Prints input and output nodes names, take notes of them.\n",
    "print(input_names, output_names)\n",
    "\n",
    "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TRT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,\n",
    "    outputs=output_names,\n",
    "    max_batch_size=1,\n",
    "    max_workspace_size_bytes=1 << 25,\n",
    "    precision_mode='FP16',\n",
    "    minimum_segment_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the TRT Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_io.write_graph(trt_graph, \"./converted_trt_graph/\",\n",
    "                     \"trt_graph.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_model_fname = './converted_trt_graph/'\n",
    "\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "#K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "#trt_model = tf.keras.models.load_model(trt_model_fname, custom_objects={'AnchorBoxes': AnchorBoxes,'compute_loss': ssd_loss.compute_loss})\n",
    "trt_model = tf.compat.v1.saved_model.loader.load(trt_model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pb file to .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pb_model_dir = \"./converted_trt_graph/\"\n",
    "h5_model = \"./mymodel.h5\"\n",
    "\n",
    "# Loading the Tensorflow Saved Model (PB)\n",
    "model = tf.keras.models.load_model(pb_model_dir)\n",
    "print(model.summary())\n",
    "\n",
    "# Saving the Model in H5 Format\n",
    "tf.keras.models.save_model(model, h5_model)\n",
    "\n",
    "# Loading the H5 Saved Model\n",
    "loaded_model_from_h5 = tf.keras.models.load_model(h5_model)\n",
    "print(loaded_model_from_h5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "GRAPH_PB_PATH = './converted_trt_graph/saved_model.pb'\n",
    "with tf.Session() as sess:\n",
    "   print(\"load graph\")\n",
    "   with gfile.FastGFile(GRAPH_PB_PATH,'rb') as f:\n",
    "       graph_def = tf.GraphDef()\n",
    "   graph_def.ParseFromString(f.read())\n",
    "   sess.graph.as_default()\n",
    "   tf.import_graph_def(graph_def, name='')\n",
    "   graph_nodes=[n for n in graph_def.node]\n",
    "   names = []\n",
    "   for t in graph_nodes:\n",
    "      names.append(t.name)\n",
    "    \n",
    "    # print operations\n",
    "\n",
    "   print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_input = tf_sess.graph.get_tensor_by_name('input_1:0')\n",
    "print(tf_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_predictions = tf_sess.graph.get_tensor_by_name('predictions/concat:0')\n",
    "print(tf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = './1478899159823020309.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image = Image.open(IMAGE_PATH)\n",
    "\n",
    "plt.imshow(image)\n",
    "\n",
    "image_resized = np.array(image.resize((480, 300)))\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    set_session(sess)\n",
    "    inputs1, predictions1 = tf_sess.run([tf_input, tf_predictions], feed_dict={\n",
    "    tf_input: image_resized[None, ...]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess.run(tf_predictions, feed_dict={\n",
    "    tf_input: image_resized[None, ...]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
